---
title: "Multidimensional Two Parameter Logistic Model"
author: "Erick A. Chacon-Montalvan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Two Parameter Logistic Model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::opts_chunk$set(fig.width = 7, fig.height = 4)
# knitr::opts_chunk$set(fig.width = 6, fig.height = 4)
knitr::opts_chunk$set(comment = "#>")
options(width = 100)
```

In this vignette, we show how to use the **spmirt** package to fit a
multidimensional 2 parameter logistic model used in item response theory. Let
$Y_{ij}$ be the response for item
$j$ in the individual $i$. The model can be defined by using an auxiliary variable
$Z_{ij}$ such as
\begin{align}
  {Y}_{ij}  & =
  \left\lbrace
  \begin{array}[2]{cc}
    1 & \text{if} ~ {Z}_{ij} > 0\\
    0 & \text{otherwise}
  \end{array}
  \right.\\
  {Z}_{ij} & = c_j + a_j^\intercal\theta_i + \epsilon_{ij},
  ~~ \epsilon_{ij} \sim {N}(0, 1)\\
  {\theta}_i & \sim {N}({0}, {I}_m)\\
  c_j & \sim {N}(0, \sigma_c^2)\\
  {a}_j & \sim {N}(0, \sigma_a^2{I}_m)\\
\end{align}

### Required packages

```{r}
rm(list = ls())
library(spmirt)
library(datasim)
library(tidyverse)
```

### Simulation of the data


First, we define the parameters for the item response model.

```{r}

q <- q1 <- q2 <- 10
n <- 300
difficulty <- matrix((1:q - 5)/10 * 2, nrow = 1)
discrimination1 <- matrix(seq(0.4, 1.5, length.out = q), nrow = 1)
discrimination2 <- matrix(runif(q, 0, 2), nrow = 1)
discrimination1[1,1] = 1
discrimination2[1,2] = 1
discrimination2[1,1] <- 0

```

```{r, echo = FALSE, results = 'asis'}

cbind(t(difficulty), t(discrimination1), t(discrimination2)) %>%
  magrittr::set_colnames(c("difficulty", "discrimination1", "discrimination2")) %>%
  knitr::kable()

```

Now we simulate the data using the `datasim` package.

```{r}

f <- list(
  prob ~ mfa(ones, beta = get("difficulty")) +
    re(id, sigma = 1, q = get("q1")):mfa(ones, beta = get("discrimination1")) +
    re(id, sigma = 1, q = get("q2")):mfa(ones, beta = get("discrimination2")),
  size ~ I(1)
  )

data_long <- sim_model(formula = f,
                        link_inv = list(pnorm, identity),
                        generator = rbinom,
                        responses = q,
                        n = n
                        )

data_long <- dplyr::rename(data_long, subject = id, ability1 = re.id.prob,
                           ability2 = re.id.prob.1,
                           item = response_label, y = response)

```

```{r, echo = FALSE, results = 'asis'}
knitr::kable(head(data_long, 20))
```

### Exploratory analysis

We can see the relationship between the latent abilities and the proportion of
endorsed items.

```{r}
explor <- data_long %>%
  group_by(subject) %>%
  summarize(endorse = mean(y),
            ability1 = unique(ability1),
            ability2 = unique(ability2))
ggplot(explor, aes(ability1, endorse)) + geom_point(alpha = 0.5)
ggplot(explor, aes(ability2, endorse)) + geom_point(alpha = 0.5)
```


## Fitting the model

```{r}

iter <- 5 * 10 ^ 4
disc_mat <- cbind(t(discrimination1), t(discrimination2))
L_a <- lower.tri(disc_mat, diag = TRUE) * 1
theta_init <- c(data_long$ability1[1:n], data_long$ability2[1:n])
a_init <- as.numeric(t(disc_mat))
a_mean <- matrix(0, q, 2)
diag(a_mean) <- 1
# a_mean[1,] <- 1

# Rcpp::sourceCpp("../src/ifa-main.cpp")
Rcpp::sourceCpp("../src/ifa-driver.cpp")
source("../R/spmirt.R")
source("../R/ggplot-mcmc.R")

system.time(
samples <- spmirt(response = data_long$y,
                  nobs = n, nitems = q, nfactors = 2, niter = iter,
                  constrains = list(A = L_a),
                  c_opt = list(prior_mean = 1, prior_sd = 1),
                  A_opt = list(prior_mean = a_mean, prior_sd = 1),
                  theta_init)
)

(samples <- spmirt(response = data_long$y,
                  nobs = n, nitems = 2, nfactors = 2, niter = iter,
                  A_opt = list(initial = 1, prior_mean = 2, prior_sd = 0.5),
                  ))




```

### Convert to tibble, burn-in, thinning, select

```{r, results = 'asis'}

# Tibble as wide format: default
samples_tib <- as_tibble(samples, burnin = iter / 2, thin = 1)
knitr::kable(samples_tib[1:10, 1:15], digits = 2)
# Tibble as long format: default
samples_long <- gather(samples_tib)
knitr::kable(head(samples_long, 10), digits = 2)
```

### Visualize trace-plots

```{r, fig.height = 6}

as_tibble(samples, 0, 10, select = "c") %>%
  gg_trace(alpha = 0.6)

as_tibble(samples, 0, 10, select = "a") %>%
  gg_trace(alpha = 0.6)

as_tibble(samples, 0, 10, select = "theta") %>%
  select(1:10, 301:310) %>%
  gg_trace(alpha = 0.6)

```

### Visualize trace on 2d

Sampling of the first two discrimination parameters.

```{r, fig.height = 6}

as_tibble(samples, 0, 10, "a") %>%
  gg_scatter(`Discrimination 1`, `Discrimination 2`, each = 10,
               keys = c("Item ", "Discrimination "),
               highlight = c(discrimination1, discrimination2), ncol = 4,
               points_alpha = 0.2)


```

### Density Plots

```{r}

as_tibble(samples, iter/2, 10, "c") %>%
  gg_density(alpha = 0.5, ridges = TRUE, aes(fill = Parameters), scale = 3)


as_tibble(samples, iter/2, 10, "a") %>%
  gg_density(alpha = 0.5, ridges = TRUE, aes(fill = Parameters), scale = 6)

```

```{r, fig.height = 6}

as_tibble(samples, iter/2, 10, "theta") %>%
  dplyr::select(1:50) %>%
  gg_density(aes(fill = median), alpha = 0.8, ridges = TRUE, scale = 4) +
  scale_fill_distiller(palette = "RdYlBu")

```

### 2D Density Plots

```{r, fig.height = 6}

as_tibble(samples, 0, 10, "a") %>%
  gg_density2d(`Discrimination 1`, `Discrimination 2`, each = 10,
               keys = c("Item ", "Discrimination "),
               highlight = c(discrimination1, discrimination2), ncol = 4,
               alpha = 0.2, size = 0.1) +
  scale_fill_distiller(palette = "RdYlBu")

```


### Remove burn-in and summarise parameters

```{r}

# # Organize and summarise output
# samples_after_burin <- samples %>% purrr::map(~ .[(0.6 * iter):iter, ])
# samples_params <- samples_after_burin[1:3]
# samples_params_summary <- samples_params %>%
#   map(~ apply(., 2, function (x) quantile(x, c(0.025, 0.5, 0.975)))) %>%
#   map(~ as_tibble(t(.))) %>%
#   map(~ setNames(., make.names(names(.))))
#

as_tibble(samples, iter/2, select = c("c", "a")) %>%
  summary()


```


### Credible Intervals


```{r}

as_tibble(samples, iter/ 2, select = "a") %>%
  summary() %>%
  mutate(param = c(discrimination1, discrimination2)) %>%
  gg_errorbarh(sorted = FALSE) +
  geom_point(aes(x = param), col = 3)

as_tibble(samples, iter/2, select = "c") %>%
  summary() %>%
  mutate(param = as.numeric(difficulty)) %>%
  gg_errorbar(sorted = FALSE) +
  geom_point(aes(y = param), col = 3)

as_tibble(samples, iter/2, select = "theta") %>%
  dplyr::select(1:300) %>%
  summary() %>%
  mutate(param = unique(data_long$ability1)) %>%
  gg_errorbar(sorted = TRUE) +
  geom_point(aes(y = param), col = 3)

as_tibble(samples, iter/2, select = "theta") %>%
  dplyr::select(301:600) %>%
  summary() %>%
  mutate(param = unique(data_long$ability2)) %>%
  gg_errorbar(sorted = TRUE) +
  geom_point(aes(y = param), col = 3)

```
