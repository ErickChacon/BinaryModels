---
title: "Multidimensional Two Parameter Logistic Model with Predictors"
author: "Erick A. Chacon-Montalvan"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Two Parameter Logistic Model}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(echo = TRUE, fig.align = "center")
knitr::opts_chunk$set(fig.width = 7, fig.height = 4)
# knitr::opts_chunk$set(fig.width = 6, fig.height = 4)
knitr::opts_chunk$set(comment = "#>")
options(width = 100)
# set.seed(1)
```

In this vignette, we show how to use the **spmirt** package to fit a
multidimensional 2 parameter logistic model used in item response theory. Let
$Y_{ij}$ be the response for item
$j$ in the individual $i$. The model can be defined by using an auxiliary variable
$Z_{ij}$ such as
\begin{align}
  {Y}_{ij}  & =
  \left\lbrace
  \begin{array}[2]{cc}
    1 & \text{if} ~ {Z}_{ij} > 0\\
    0 & \text{otherwise}
  \end{array}
  \right.\\
  {Z}_{ij} & = c_j + a_j^\intercal\theta_i + \epsilon_{ij},
  ~~ \epsilon_{ij} \sim {N}(0, 1)\\
  {\theta}_i & \sim {N}({0}, {I}_m)\\
  c_j & \sim {N}(0, \sigma_c^2)\\
  {a}_j & \sim {N}(0, \sigma_a^2{I}_m)\\
\end{align}

### Required packages

```{r}
rm(list = ls())
library(spmirt)
library(datasim)
library(tidyverse)
```

### Simulation of the data

Firtst, simulate correlated factors:

```{r}

m <- 2
# set.seed(4)
Corr <- matrix(c(1, -0.3, -0.3, 1), nrow = m)
sigmas <- rep(0.5^0.5, m)
D <- diag(sigmas)
Cov <- D %*% Corr %*% D
beta1 <- c(0.7, -0.3)
beta2 <- c(0.3, 0.5)

# mean ~ mre(factor(id), sigma = get("Cov")),
f <- list(
  mean ~ mfe(x1, beta = get("beta1")) +
    mfe(x2, beta = get("beta2")) +
    mre(factor(id), sigma = get("Cov")),
  sd ~ I(0)
  )

n <- 300
(data_geo <- sim_model(formula = f, n = n, responses = m))
# knitr::kable(head(data_model, 10))

ggplot(data_geo, aes(x1, response)) +
  geom_smooth(aes(col = factor(response_label))) +
  geom_point(aes(col = factor(response_label)))

ggplot(data_geo, aes(x2, response)) +
  geom_smooth(aes(col = factor(response_label))) +
  geom_point(aes(col = factor(response_label)))

data_geo %>%
  dplyr::select(id, mre.factor.mean, response_label) %>%
  spread(response_label, mre.factor.mean) %>%
  dplyr::select(-id) %>%
  GGally::ggpairs(aes(fill = "any"))

data_geo_wide <- data_geo %>%
  dplyr::rename(ability = response, id_person = id) %>%
  gather(var, value, mre.factor.mean:ability) %>%
  mutate(var = paste0(var, response_label)) %>%
  select(-response_label) %>%
  spread(var, value)


```


First, we define the parameters for the item response model.

```{r}

q <- q1 <- q2 <- 10
init_data <- purrr::map(1:q, ~ data_geo_wide) %>%
  purrr::reduce(rbind)

n <- 300
difficulty <- matrix((1:q - 5)/10 * 2, nrow = 1)
discrimination1 <- seq(0.4, 1.5, length.out = q)
discrimination2 <- runif(q, 0, 2)
discrimination1[1] = 1
discrimination2[2] = 1
discrimination2[1] <- 0
discrimination1[4] <- 0
discrimination2[5] <- 0

```

```{r, echo = FALSE, results = 'asis'}

cbind(t(difficulty), cbind(discrimination1), cbind(discrimination2)) %>%
  magrittr::set_colnames(c("difficulty", "discrimination1", "discrimination2")) %>%
  knitr::kable()

```

Now we simulate the data using the `datasim` package.

```{r}

f <- list(
  prob ~ mfa(ones, beta = get("difficulty")) +
    mfe(ability1, beta = get("discrimination1")) +
    mfe(ability2, beta = get("discrimination2")),
  size ~ I(1)
  )

data_long <- sim_model(formula = f,
                        link_inv = list(pnorm, identity),
                        generator = rbinom,
                        responses = q,
                        n = n,
                        init_data = init_data
                        )

data_long <- dplyr::rename(data_long, subject = id,
                           item = response_label, y = response)


```

```{r, echo = FALSE, results = 'asis'}
knitr::kable(head(data_long, 20))
```

### Exploratory analysis

We can see the relationship between the latent abilities and the proportion of
endorsed items.

```{r}
explor <- data_long %>%
  group_by(subject) %>%
  summarize(endorse = mean(y),
            ability1 = unique(ability1),
            ability2 = unique(ability2),
            x1 = unique(x1),
            x2 = unique(x2))
ggplot(explor, aes(ability1, endorse)) + geom_point(alpha = 0.5)
ggplot(explor, aes(ability2, endorse)) + geom_point(alpha = 0.5)

ggplot(explor, aes(x1, endorse)) + geom_point(alpha = 0.5)
ggplot(explor, aes(x2, endorse)) + geom_point(alpha = 0.5)
```


## Fitting the model

```{r}

iter <- 5 * 10 ^ 4
thin <- 10
disc_mat <- cbind(cbind(discrimination1), cbind(discrimination2))
L_a <- lower.tri(disc_mat, diag = TRUE) * 1
L_a[4,1] <- 0
L_a[5,2] <- 0

# L_a <- matrix(1, q, 2)
# L_a[c(1, 5, 8, 16)] <- 0
theta_init <- c(data_long$ability1[1:n], data_long$ability2[1:n])
a_init <- as.numeric(t(disc_mat))
a_mean <- matrix(0, q, 2)
diag(a_mean) <- 1
# a_mean[1,] <- 1

predictors <- as.matrix(dplyr::select(data_geo_wide, x1:x2))

# Rcpp::sourceCpp("../src/correlation.cpp")
# Rcpp::sourceCpp("../src/ifa-main.cpp")
Rcpp::sourceCpp("../src/ifa-driver.cpp")
source("../R/spmirt.R")
source("../R/ggplot-mcmc.R")

# iter = 10^2
# thin = 1
system.time(
samples <- spmirt(
  response = data_long$y, predictors = predictors, coordinates = NULL,
  nobs = n, nitems = q, nfactors = 2, niter = iter, thin = thin,
  constrains = list(A = L_a, V_sd = sigmas) ,
  # adaptive = list(Sigma_R = matrix(0.001, 1,1))
  A_opt = list(initial = L_a),
  R_opt = list(prior_eta = 1)
)
)
attr(samples, "model")
iter <- iter / thin


attr(samples, "model_info")[-c(1,2,3)]

#
# Rcpp::sourceCpp("../src/pdf.cpp")
# (bla <- rnorm(6))
# bla <- 0
# vec2chol_corr(bla, 4)
# vec2chol_corr2(bla, 4)
#
# (bla <- 0)
# dlkj_corr_free(bla, 2, 1)
# dlkj_corr_free2(bla, 2, 1)
#
#
# dlkj_corr(diag(2), 1.5)
# dlkj_corr(matrix(c(1, 0.5, 0.5, 1), 2), 1.5)

# dlkj_corr_free(0.000001, 2, 1)

# samples[["A_prior_mean"]]
# samples[["A_prior_sd"]]
# samples[["constrain_L"]]
# samples[["constrain_T"]]


  # constrains = list(A = L_a),
  # adaptive = list(Sigma = NULL, Sigma_R = NULL, Sigma_gp_sd = 1:3,
  # Sigma_gp_phi = NULL),
  # c_opt = list(prior_mean = 0, prior_sd = 1),
  # A_opt = list(prior_mean = a_mean, prior_sd = 1)
  # )

# (samples <- spmirt(response = data_long$y,
# nobs = n, nitems = 2, nfactors = 2, niter = iter,
# A_opt = list(initial = 1, prior_mean = 2, prior_sd = 0.5),
# ))


# (samples <- spmirt(
# response = data_long$y,
# nobs = n, nitems = 4, nfactors = 3, niter = iter,
# constrains = list(A = NULL, W = NULL),
# adaptive = list(Sigma_R = 1, Sigma_gp_sd = 1, Sigma_gp_phi = 1,
# scale = 1, C = 0.7, alpha = 0.8, accep_prob = 0.234),
# c_opt = list(initial = NULL, prior_mean = NULL, prior_sd = NULL),
# A_opt = list(prior_mean = 1, prior_sd = 1)
# )
# )


```

### Convert to tibble, burn-in, thinning, select

```{r, results = 'asis'}

# Tibble as wide format: default
samples_tib <- as_tibble(samples, burnin = iter / 2, thin = 1)

knitr::kable(samples_tib[1:10, 1:15], digits = 2)

# Tibble as long format: default
samples_long <- gather(samples_tib)
knitr::kable(head(samples_long, 10), digits = 2)
```

### Visualize trace-plots

```{r, fig.height = 6}

as_tibble(samples, 0, 10, select = "c") %>%
  gg_trace(alpha = 0.6)

as_tibble(samples, 0, 10, select = "a") %>%
  gg_trace(alpha = 0.6)

as_tibble(samples, 0, 10, select = "theta") %>%
  select(1:10, 301:310) %>%
  gg_trace(alpha = 0.6)

as_tibble(samples, 0, 1, select = "corr") %>%
  gg_trace(alpha = 0.6)

as_tibble(samples, 0, 1, select = "betas") %>%
  gg_trace(alpha = 0.6)


```

```{r}
# 
# bla <- as_tibble(samples, 0, 1, select = "theta")
# 
# cst <- 105
# cor(bla[c(cst + 1, cst + 301)])
# 
# %>%
# select(1:10, 301:310) %>%
# gg_trace(alpha = 0.6)


```

### Visualize trace on 2d

Sampling of the first two discrimination parameters.

```{r, fig.height = 6}

as_tibble(samples, 0, 10, "a") %>%
  gg_scatter(`Discrimination 1`, `Discrimination 2`, each = 10,
               keys = c("Item ", "Discrimination "),
               highlight = c(discrimination1, discrimination2), ncol = 4,
               points_alpha = 0.2)


```

### Density Plots

```{r}

as_tibble(samples, iter/2, 10, "c") %>%
  gg_density(alpha = 0.5, ridges = TRUE, aes(fill = Parameters), scale = 3)


as_tibble(samples, iter/2, 10, "a") %>%
  gg_density(alpha = 0.5, ridges = TRUE, aes(fill = Parameters), scale = 6)

```

```{r, fig.height = 6}

as_tibble(samples, iter/2, 10, "theta") %>%
  dplyr::select(1:50) %>%
  gg_density(aes(fill = median), alpha = 0.8, ridges = TRUE, scale = 4) +
  scale_fill_distiller(palette = "RdYlBu")

```

### 2D Density Plots

```{r, fig.height = 6}

as_tibble(samples, 0, 10, "a") %>%
  gg_density2d(`Discrimination 1`, `Discrimination 2`, each = 10,
               keys = c("Item ", "Discrimination "),
               highlight = c(discrimination1, discrimination2), ncol = 4,
               alpha = 0.2, size = 0.1) +
  scale_fill_distiller(palette = "RdYlBu")

```


### Remove burn-in and summarise parameters

```{r}

# # Organize and summarise output
# samples_after_burin <- samples %>% purrr::map(~ .[(0.6 * iter):iter, ])
# samples_params <- samples_after_burin[1:3]
# samples_params_summary <- samples_params %>%
#   map(~ apply(., 2, function (x) quantile(x, c(0.025, 0.5, 0.975)))) %>%
#   map(~ as_tibble(t(.))) %>%
#   map(~ setNames(., make.names(names(.))))
#

as_tibble(samples, iter/2, select = c("c", "a")) %>%
  summary()


```


### Credible Intervals


```{r}

as_tibble(samples, iter/ 2, select = "a") %>%
  summary() %>%
  mutate(param = c(discrimination1, discrimination2)) %>%
  gg_errorbarh(sorted = FALSE) +
  geom_point(aes(x = param), col = 3)

as_tibble(samples, iter/2, select = "c") %>%
  summary() %>%
  mutate(param = as.numeric(difficulty)) %>%
  gg_errorbar(sorted = FALSE) +
  geom_point(aes(y = param), col = 3)

as_tibble(samples, iter/2, select = "theta") %>%
  dplyr::select(1:300) %>%
  summary() %>%
  mutate(param = unique(data_long$ability1)) %>%
  gg_errorbar(sorted = TRUE) +
  geom_point(aes(y = param), col = 3)

as_tibble(samples, iter/2, select = "theta") %>%
  dplyr::select(301:600) %>%
  summary() %>%
  mutate(param = unique(data_long$ability2)) %>%
  gg_errorbar(sorted = TRUE) +
  geom_point(aes(y = param), col = 3)

```
